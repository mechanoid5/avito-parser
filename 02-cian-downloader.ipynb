{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e37d325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import logging\n",
    "from datetime import datetime as dtm\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "202ec0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "tqdm.pandas()\n",
    "\n",
    "logging.basicConfig(\n",
    "        format=u'[%(levelname)-8s] %(asctime)s | %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        level=logging.INFO,\n",
    "        # level=logging.DEBUG,\n",
    "        stream=sys.stdout,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c481fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.cian.ru/cat.php?deal_type=sale&engine_version=2&offer_type=flat&region=184723\n",
    "# https://www.cian.ru/cat.php?deal_type=sale&offer_type=flat&region=184723"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b47fdd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url='https://www.cian.ru/cat.php'\n",
    "req_param='deal_type=sale&offer_type=flat&region=184723'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac5760d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.parser import AdsListParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b869c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CianParser(AdsListParser):\n",
    "    \n",
    "    def __init__(self,driver):\n",
    "        super().__init__(\n",
    "            driver=driver, \n",
    "            base_url='https://www.cian.ru/cat.php',\n",
    "            item_tag=['article',{'data-name':'CardComponent',},],\n",
    "            paginator_url_param='p',\n",
    "        )\n",
    "        logging.info('CianParser: downloader init')\n",
    "    \n",
    "    def _is_last_page(self,root,p): \n",
    "        try:\n",
    "            paginator = root.find('div',{'data-name':'Pagination',})\n",
    "            pl = [ tag.text for tag in root.find_all('li') ][-1]\n",
    "            return str(p)==pl\n",
    "        except Exception as e:\n",
    "            logging.warning(f'CianParser: parse pagination error: {e}')\n",
    "            return True\n",
    "        \n",
    "    def _parse_item(self,tag): \n",
    "        return { \n",
    "             'OfferTitle': self._get_title(tag),\n",
    "          'OfferSubtitle': self._get_subtitle(tag),\n",
    "               'Deadline': self._get_deadline(tag),\n",
    "              'MainPrice': self._get_price(tag),\n",
    "              'PriceInfo': self._get_price_m(tag),\n",
    "               'GeoLabel': self._get_adr(tag),\n",
    "              'TimeLabel': self._get_ts( tag ),  \n",
    "               'LinkArea': self._get_link( tag ),\n",
    "            'Description': self._get_descr(tag),\n",
    "                        \n",
    "            }\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_deadline(tag):\n",
    "        try:\n",
    "            return tag.find('span',{'data-mark':'Deadline',}).text\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    @staticmethod\n",
    "    def _get_title(tag):\n",
    "        try:\n",
    "            return tag.find('span',{'data-mark':'OfferTitle',}).text\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    @staticmethod\n",
    "    def _get_subtitle(tag):\n",
    "        try:\n",
    "            return tag.find('span',{'data-mark':'OfferSubtitle',}).text\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    @staticmethod\n",
    "    def _get_price(tag):\n",
    "        try:\n",
    "            return tag.find('span',{'data-mark':'MainPrice',}).text\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_price_m(tag):\n",
    "        try:\n",
    "            return tag.find('p',{'data-mark':'PriceInfo',}).text\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    @staticmethod\n",
    "    def _get_adr(tag):\n",
    "        try:\n",
    "            return [ t.text for t in tag.find_all('a',{'data-name':'GeoLabel',}) ]\n",
    "        except:\n",
    "            return []\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_ts(tag):\n",
    "        try:\n",
    "            tag_ = tag.find('div',{'data-name':'TimeLabel',})\n",
    "            return [ t.text for t in tag_.find_all('span') ]\n",
    "        except:\n",
    "            return []\n",
    "        \n",
    "    @staticmethod\n",
    "    def _get_link(tag):\n",
    "        try:\n",
    "            return tag.find('div',{'data-name':'LinkArea',}).find('a').attrs['href']\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    @staticmethod\n",
    "    def _get_descr(tag):\n",
    "        try:\n",
    "            return tag.find('div',{'data-name':'Description',}).text\n",
    "        except:\n",
    "            return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6c0ce1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e42986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO    ] 2022-09-07 13:21:24 | DownloaderSeleniumFirefox: downloader init\n",
      "[INFO    ] 2022-09-07 13:21:24 | DownloaderSeleniumFirefox: open virtual browser\n",
      "[INFO    ] 2022-09-07 13:21:26 | AdsListParser: downloader init\n",
      "[INFO    ] 2022-09-07 13:21:26 | CianParser: downloader init\n",
      "[INFO    ] 2022-09-07 13:21:26 | AdsListParser: start read and parse pages...\n",
      "[INFO    ] 2022-09-07 13:21:29 | AdsListParser: read page 1\n",
      "[WARNING ] 2022-09-07 13:21:29 | CianParser: parse pagination error: list index out of range\n",
      "[INFO    ] 2022-09-07 13:21:29 | AdsListParser: last page detected\n",
      "[INFO    ] 2022-09-07 13:21:29 | DownloaderSeleniumFirefox: close virtual browser\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "profile_path = '/home/mechanoid/.mozilla/firefox/p144xo2m.default-release'\n",
    "from lib.downloader import DownloaderSeleniumFirefox\n",
    "\n",
    "df,html = CianParser(\n",
    "        driver=DownloaderSeleniumFirefox(profile_path)\n",
    "    ).load(req_param, keep_html=True, page_limit=3 )\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "724a9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc01b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lib.downloader import DownloaderSimple\n",
    "# df,html = CianParser(driver=DownloaderSimple()).load(req_param, keep_html=True, page_limit=3)\n",
    "# # html = DownloaderSimple().get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db0e1b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmp/cian.html','wt') as f: f.write(html[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce966c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cce38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d92d19",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lib.downloader import DownloaderSimple\n",
    "# html = DownloaderSimple().get(url)\n",
    "# with open('tmp/cian_.html','wt') as f: f.write(html[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537ff1e5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44159948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <article data-name=\"CardComponent\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d974e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# <span data-mark=\"OfferTitle\"\n",
    "# <span data-mark=\"OfferSubtitle\" \n",
    "# <span data-mark=\"Deadline\"\n",
    "\n",
    "# <a data-name=\"GeoLabel\"\n",
    "\n",
    "# <span data-mark=\"MainPrice\"\n",
    "\n",
    "# <p data-mark=\"PriceInfo\" \n",
    "\n",
    "# <div data-name=\"Description\" \n",
    "\n",
    "# <div data-name=\"LinkArea\" class=\"_93444fe79c--container--kZeLu _93444fe79c--link--DqDOy\">\n",
    "# <a href=\"https://sevastopol.cian.ru/sale/flat/273181085/\" class=\"_93444fe79c--link--eoxce\">\n",
    "\n",
    "# <div data-name=\"TimeLabel\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_link(tag):\n",
    "#     return tag.find('a').attrs['href']\n",
    "\n",
    "# def get_ts(tag):\n",
    "#     return [ t.text for t in tag.find_all('span') ]\n",
    "\n",
    "# def get_adr(tag):\n",
    "#     return [ t.text for t in tag.find_all('a',{'data-name':'GeoLabel',}) ]\n",
    "\n",
    "# def parse_item(tag):\n",
    "#     return {\n",
    "#     'OfferTitle':tag.find('span',{'data-mark':'OfferTitle',}).text,\n",
    "    \n",
    "#     #'OfferSubtitle': tag.find('span',{'data-mark':'OfferSubtitle',}).text,\n",
    "#     # 'Deadline': tag.find('span',{'data-mark':'Deadline',}).text,\n",
    "    \n",
    "#     'GeoLabel':  get_adr(tag),  # tag.find('span',{'data-name':'GeoLabel',}).text,\n",
    "        \n",
    "#     'MainPrice': tag.find('span',{'data-mark':'MainPrice',}).text,\n",
    "#     'PriceInfo': tag.find('p',{'data-mark':'PriceInfo',}).text,\n",
    "#     'Description': tag.find('div',{'data-name':'Description',}).text,\n",
    "#     'LinkArea': get_link( tag.find('div',{'data-name':'LinkArea',})), \n",
    "#     'TimeLabel': get_ts( tag.find('div',{'data-name':'TimeLabel',})),  \n",
    "#     }\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86473212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = BeautifulSoup(html,'html.parser')\n",
    "# text = [\n",
    "#     parse_item(tag)\n",
    "#     for tag in root.find_all('article',{'data-name':'CardComponent',}) \n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a184dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48fe19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6da2ead",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffb0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "# class AvitoDownloader:\n",
    "    \n",
    "#     def __init__(self,driver, base_url='https://www.avito.ru'):\n",
    "#         logging.info('AvitoDownloader: downloader init')\n",
    "#         self._base_url = base_url\n",
    "#         self._driver = driver # ссылка на открытый браузер\n",
    "        \n",
    "        \n",
    "#     # загрузить список объявлений Авито\n",
    "#     # из раздела url_ext ( 'sevastopol/kvartiry/prodam' )\n",
    "#     # не более page_limit страниц (если неопределенно то все страницы)\n",
    "#     def load(self, avito_path, page_limit=None, show_pbar=False, keep_html=False): \n",
    "#         html = [] # считанный \"чистый\" html\n",
    "#         data = [] # данные извлечённые парсером из html\n",
    "#         try:\n",
    "#             if re.match('^http.*',avito_path):\n",
    "#                 logging.warning('AvitoDownloader: incorrect avito_path')\n",
    "\n",
    "#             url = self._base_url + '/' + avito_path + '?'\n",
    "            \n",
    "#             # читаем и парсим оставшиеся страницы списка объявлений (начиная со второй)\n",
    "#             logging.info('AvitoDownloader: start read and parse pages...')\n",
    "\n",
    "#             page,root,src = self._read_page(url) # читаем и парсим первую страницу списка объявлений\n",
    "#             data.extend(page)\n",
    "#             if keep_html: html.append(src)\n",
    "                \n",
    "#             # считываем количество страниц, на которые поделен список объявлений\n",
    "#             npages = self._get_pages_count(root,page_limit=page_limit)\n",
    "            \n",
    "#             npages_ = tqdm(range(2,npages+1)) if show_pbar else range(2,npages+1)\n",
    "#             for p in npages_: \n",
    "#                 # читаем и парсим страницу p списка объявлений\n",
    "#                 page,_,src = self._read_page(url+f'&p={p}',npage=p) \n",
    "#                 data.extend(page)\n",
    "#                 if keep_html: html.append(src)\n",
    "                           \n",
    "#         except Exception as e:\n",
    "#             logging.error(e) # перехватываем и логируем описания возникших ошибок\n",
    "\n",
    "#         finally: # завершение процесса чтения\n",
    "#             data = pd.DataFrame(data).dropna()\n",
    "#             data['ts']  = dtm.now()\n",
    "#             # выдаём список полученных объявлений и их исходный html\n",
    "#             return (data,html) if keep_html else data \n",
    "                 \n",
    "          \n",
    "#     # читаем страницу Авито по url\n",
    "#     def _read_page(self,url,npage=1): \n",
    "#         html = self._driver.get(url)\n",
    "#         root = BeautifulSoup(html,'html.parser')\n",
    "#         return self._parse_page(root,npage=npage),root, html,  \n",
    "\n",
    "#     @classmethod\n",
    "#     def _parse_page(cls, root, npage):\n",
    "#         return [ \n",
    "#             cls._parse_item(tag)|{'avito_page':npage,} \n",
    "#             for tag in root.find_all('div',{'data-marker':'item'}) \n",
    "#         ]\n",
    "        \n",
    "#     @staticmethod\n",
    "#     def _parse_item(tag): \n",
    "#         return { 'avito_id': tag.attrs['data-item-id'], 'text':tag.text, } # { 'html':str(tag), }\n",
    "\n",
    "#     @classmethod\n",
    "#     def _get_pages_count(cls,root,page_limit):\n",
    "#         pages = cls._parse_pages_count(root)\n",
    "#         logging.info(f'{pages} pages for read')\n",
    "#         if not(page_limit is None): \n",
    "#             pages = min(pages,page_limit+1)\n",
    "#             logging.info(f'apply page limit - {pages} pages')\n",
    "#         return pages\n",
    "            \n",
    "#     @staticmethod\n",
    "#     def _parse_pages_count(root):\n",
    "#         pp = re.sub( r'.*?p=', '', root.find_all('a',{'class':'pagination-page'})[-1].attrs['href'] ) \n",
    "#         return 1 if not re.match(r'\\d{1,3}', pp) else int(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270fc4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "# class AvitoDownloaderRealty(AvitoDownloader):\n",
    "    \n",
    "#     @classmethod\n",
    "#     def _parse_item(cls,tag):\n",
    "#         return {    \n",
    "#             'avito_id': tag.attrs['data-item-id'],   # https://www.avito.ru/<avito_id>\n",
    "#             'title': cls._parse_item_tile(tag),\n",
    "#             'price': cls._parse_item_price(tag),\n",
    "#             'obj_name': cls._parse_item_dev_name(tag),\n",
    "#             'adr': cls._parse_item_adr(tag),\n",
    "#             'description': cls._parse_item_description(tag),\n",
    "#             }\n",
    "        \n",
    "#     @staticmethod\n",
    "#     def _parse_item_tile(tag):\n",
    "#         try:\n",
    "#             return tag.find('a',attrs={'itemprop':'url'}).attrs['title']\n",
    "#         except:\n",
    "#             return ''    \n",
    "      \n",
    "#     @staticmethod\n",
    "#     def _parse_item_price(tag):\n",
    "#         try:\n",
    "#             return tag.find('meta',attrs={'itemprop':'price'}).attrs['content']\n",
    "#         except:\n",
    "#             return ''\n",
    "        \n",
    "#     @staticmethod\n",
    "#     def _parse_item_dev_name(tag):\n",
    "#         try:\n",
    "#             return tag.find('div',{'data-marker':'item-development-name'}).text\n",
    "#         except:\n",
    "#             return '' \n",
    "           \n",
    "#     @staticmethod\n",
    "#     def _parse_item_adr(tag):\n",
    "#         regex_address = re.compile('geo-address-.*')\n",
    "#         try:\n",
    "#             return tag.find('span',{'class':regex_address}).text\n",
    "#         except:\n",
    "#             return '' \n",
    "            \n",
    "#     @staticmethod\n",
    "#     def _parse_item_description(tag):\n",
    "#         regex_address = re.compile('geo-address-.*')\n",
    "#         try:\n",
    "#             return tag.find('meta',attrs={'itemprop':'description'}).attrs['content']\n",
    "#         except:\n",
    "#             return ''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a8463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AdsListParser:\n",
    "    \n",
    "#     def __init__( self,driver, base_url, item_tag, paginator_url_param='p', ):\n",
    "#         logging.info('AdsListParser: downloader init')\n",
    "#         self._base_url = base_url\n",
    "#         self._paginator_url_param = paginator_url_param\n",
    "#         self._driver = driver\n",
    "#         self._item_tag = item_tag # ['article',{'data-name':'CardComponent',}]\n",
    "\n",
    "#     # загрузить список объявлений не более page_limit страниц \n",
    "#     def load(self, req_param, page_limit=200, keep_html=False): \n",
    "#         html = [] # считанный \"чистый\" html\n",
    "#         data = [] # данные извлечённые парсером из html\n",
    "#         try:\n",
    "#             url = self._base_url + '?' + req_param\n",
    "            \n",
    "#             # читаем и парсим оставшиеся страницы списка объявлений (начиная со второй)\n",
    "#             logging.info('AdsListParser: start read and parse pages...')\n",
    "\n",
    "#             for p in range(1,page_limit):\n",
    "#                 # читаем и парсим страницу p списка объявлений\n",
    "#                 page,root,src = self._read_page(url+f'&{self._paginator_url_param}={p}',npage=p) \n",
    "#                 data.extend(page)\n",
    "#                 if keep_html: html.append(src)\n",
    "#                 logging.info(f'AdsListParser: read page {p}')\n",
    "#                 if self._is_last_page(root,p): \n",
    "#                     logging.info('AdsListParser: last page detected')\n",
    "#                     break\n",
    "                                                \n",
    "#         except Exception as e:\n",
    "#             logging.error(e) # перехватываем и логируем описания возникших ошибок\n",
    "\n",
    "#         finally: # завершение процесса чтения\n",
    "#             data = pd.DataFrame(data).dropna()\n",
    "#             data['ts']  = dtm.now()\n",
    "#             # выдаём список полученных объявлений и их исходный html\n",
    "#             return (data,html) if keep_html else data \n",
    "          \n",
    "#     # читаем страницу по url\n",
    "#     def _read_page(self,url,npage=1): \n",
    "#         html = self._driver.get(url)\n",
    "#         root = BeautifulSoup(html,'html.parser')\n",
    "#         return self._parse_page(root,npage=npage),root, html,  \n",
    "\n",
    "#     def _parse_page(self, root, npage):\n",
    "#         return [ \n",
    "#             self._parse_item(tag)|{'page':npage,} \n",
    "#             for tag in root.find_all( *self._item_tag )\n",
    "#         ]\n",
    "    \n",
    "#     def _parse_item(self,tag): \n",
    "#         return { 'text': tag.text, }\n",
    "\n",
    "#     def _is_last_page(self,root,p): \n",
    "#         return True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
